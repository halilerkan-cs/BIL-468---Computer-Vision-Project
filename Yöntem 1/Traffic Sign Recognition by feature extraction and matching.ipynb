{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82d57a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import skimage.data\n",
    "import skimage.transform\n",
    "import skimage.io\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "\n",
    "# Allow image embeding in notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "373042f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dir):\n",
    "    \"\"\"Loads a data set and returns two lists:\n",
    "    \n",
    "    images: a list of Numpy arrays, each representing an image.\n",
    "    labels: a list of numbers that represent the images labels.\n",
    "    \"\"\"\n",
    "    # Get all subdirectories of data_dir. Each represents a label.\n",
    "    directories = [d for d in os.listdir(data_dir) \n",
    "                   if os.path.isdir(os.path.join(data_dir, d))]\n",
    "    # Loop through the label directories and collect the data in\n",
    "    # two lists, labels and images.\n",
    "    labels = []\n",
    "    images = []\n",
    "    for d in directories:\n",
    "        label_dir = os.path.join(data_dir, d)\n",
    "        file_names = [os.path.join(label_dir, f) \n",
    "                      for f in os.listdir(label_dir) if f.endswith(\".jpg\")]\n",
    "        # For each label, load it's images and add them to the images list.\n",
    "        # And add the label number (i.e. directory name) to the labels list.\n",
    "        for f in file_names:\n",
    "            images.append(skimage.io.imread(f))\n",
    "            labels.append(int(d))\n",
    "    return images, labels\n",
    "\n",
    "\n",
    "# Load training and testing datasets.\n",
    "#ROOT_PATH = \"/traffic\"\n",
    "train_data_dir = os.path.join( r'C:\\Users\\halil\\Downloads\\GTSRB\\crop_dataset\\crop_dataset')\n",
    "test_data_dir = os.path.join( r'C:\\Users\\halil\\Downloads\\GTSRB\\test_data\\test_data')\n",
    "\n",
    "images, labels = load_data(train_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6527ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Labels: 43\n",
      "Total Images: 26640\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique Labels: {0}\\nTotal Images: {1}\".format(len(set(labels)), len(images)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0291ea5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feature extracing method ##\n",
    "\n",
    "def extract_and_match_features(image_path, database_templates):\n",
    "    # Görüntüyü gri tonlamaya dönüştür\n",
    "    gray_image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    # SIFT özellik çıkarıcıyı oluştur\n",
    "    sift = cv2.SIFT_create()\n",
    "    \n",
    "    # Keypoint'leri ve tanımlayıcıları bul\n",
    "    keypoints, descriptors = sift.detectAndCompute(gray_image, None)\n",
    "    \n",
    "    # Veritabanındaki şablonlarla eşleştirme\n",
    "    matches = []\n",
    "    for template in database_templates:\n",
    "        template_keypoints, template_descriptors = template\n",
    "        \n",
    "        # BFMatcher kullanarak özellikleri eşleştir\n",
    "        bf = cv2.BFMatcher()\n",
    "        template_matches = bf.knnMatch(descriptors, template_descriptors, k=2)\n",
    "        \n",
    "        # İyi eşleşmeleri seç\n",
    "        good_matches = []\n",
    "        for match in template_matches:\n",
    "            if len(match) == 2:  # Eğer eşleşme listesi beklenen uzunluktaysa\n",
    "                m, n = match\n",
    "                if m.distance < 1 * n.distance:\n",
    "                    good_matches.append(m)\n",
    "        \n",
    "        # Eşleşme sayısını kaydet\n",
    "        if len(good_matches) > 10:  # Örnek bir eşik değeri, ihtiyacınıza göre ayarlayabilirsiniz\n",
    "            matches.append((len(good_matches), template))\n",
    "    \n",
    "    # Eğer uygun bir eşleşme yoksa\n",
    "    if not matches:\n",
    "        return None\n",
    "    \n",
    "    # En fazla eşleşme sayısına sahip olanı seç\n",
    "    recognized_sign = max(matches, key=lambda x: x[0])[1]\n",
    "    \n",
    "    # En iyi eşleşen şablonun (trafik işaretinin) tanımlayıcıları döndürülür\n",
    "    return recognized_sign\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3b753da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of templates: 43\n"
     ]
    }
   ],
   "source": [
    "## DATABASE TEMPLATE OLUŞTURMA ##\n",
    "\n",
    "# Database_templates'ı saklamak için liste\n",
    "database_templates = []\n",
    "\n",
    "# Meta klasöründeki tüm görüntüler için döngü\n",
    "meta_folder_path = r'C:\\Users\\halil\\Downloads\\GTSRB\\Meta'\n",
    "for meta_filename in os.listdir(meta_folder_path):\n",
    "    # Meta resminin yolunu oluştur\n",
    "    meta_image_path = os.path.join(meta_folder_path, meta_filename)\n",
    "    \n",
    "    # Meta resmini yükle\n",
    "    meta_image = cv2.imread(meta_image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    # SIFT özellik çıkarıcıyı oluştur\n",
    "    sift = cv2.SIFT_create()\n",
    "    \n",
    "    # Keypoint'leri ve desenleri bul\n",
    "    keypoints, descriptors = sift.detectAndCompute(meta_image, None)\n",
    "    \n",
    "    # Template'i ekle\n",
    "    database_templates.append((keypoints, descriptors))\n",
    "\n",
    "# Elde edilen tüm template'leri ekrana bas\n",
    "print(\"Number of templates:\", len(database_templates))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85221b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tanıma sonuçlarını saklamak için sözlük\n",
    "class_recognition_results = {}\n",
    "\n",
    "# Meta klasöründe döngü\n",
    "meta_folder_path = r'C:\\Users\\halil\\Downloads\\GTSRB\\Meta'\n",
    "total_recognized_count = 0\n",
    "total_not_recognized_count = 0\n",
    "total_count = 0\n",
    "for meta_filename in os.listdir(meta_folder_path):\n",
    "    # Meta resminin yolunu oluştur\n",
    "    meta_image_path = os.path.join(meta_folder_path, meta_filename)\n",
    "    \n",
    "    # Meta resmini yükle\n",
    "    meta_image = cv2.imread(meta_image_path)\n",
    "    \n",
    "    # Meta resminin sınıfını belirle (örneğin, dosya adından)\n",
    "    class_name = os.path.splitext(meta_filename)[0]  # Dosya adından sınıf adını al\n",
    "    \n",
    "    # Sınıfın klasör yolunu oluştur (örneğin, 00000)\n",
    "    class_folder_path = os.path.join(r'C:\\Users\\halil\\Downloads\\GTSRB\\crop_dataset\\crop_dataset', str(int(class_name)).zfill(5))\n",
    "    \n",
    "    # Sınıf klasöründeki her resim için döngü\n",
    "    recognized_count = 0\n",
    "    not_recognized_count = 0\n",
    "    total_class_count = 0\n",
    "    for image_filename in os.listdir(class_folder_path):\n",
    "        # Resmin yolunu oluştur\n",
    "        image_path = os.path.join(class_folder_path, image_filename)\n",
    "        \n",
    "        # Resmi tanı\n",
    "        recognized_sign = extract_and_match_features(image_path, database_templates)\n",
    "        \n",
    "        # Tanıma sonucunu kontrol et\n",
    "        if recognized_sign:\n",
    "            recognized_count += 1\n",
    "        else:\n",
    "            not_recognized_count += 1\n",
    "        \n",
    "        total_class_count += 1\n",
    "    \n",
    "    # Sınıf için tanıma sonuçlarını sakla\n",
    "    accuracy = recognized_count / total_class_count if total_class_count > 0 else 0.0\n",
    "    class_recognition_results[class_name] = {\n",
    "        'recognized_count': recognized_count,\n",
    "        'not_recognized_count': not_recognized_count,\n",
    "        'total_count': total_class_count,\n",
    "        'accuracy': accuracy\n",
    "    }\n",
    "    \n",
    "    # Toplam doğru ve yanlış tanınan resim sayılarını güncelle\n",
    "    total_recognized_count += recognized_count\n",
    "    total_not_recognized_count += not_recognized_count\n",
    "    total_count += total_class_count\n",
    "\n",
    "# Toplam doğruluk hesabı\n",
    "overall_accuracy = total_recognized_count / total_count if total_count > 0 else 0.0\n",
    "\n",
    "# Sonuçları yazdır\n",
    "print(\"Overall Accuracy:\", \"{:.2%}\".format(overall_accuracy))\n",
    "print()\n",
    "for class_name, results in class_recognition_results.items():\n",
    "    print(\"Class:\", class_name)\n",
    "    print(\"Total Count:\", results['total_count'])\n",
    "    print(\"Recognized Count:\", results['recognized_count'])\n",
    "    print(\"Not Recognized Count:\", results['not_recognized_count'])\n",
    "    print(\"Accuracy:\", \"{:.2%}\".format(results['accuracy']))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8054455e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_hsv_and_filter_by_color(image):\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    color_ranges = {\n",
    "        'red': [(0, 100, 100), (10, 255, 255)],\n",
    "        'green': [(50, 100, 100), (70, 255, 255)],\n",
    "        'blue': [(110, 100, 100), (130, 255, 255)],\n",
    "        'yellow': [(25, 100, 100), (35, 255, 255)]\n",
    "    }\n",
    "    filtered_images = {}\n",
    "    for color, (lower, upper) in color_ranges.items():\n",
    "        lower_bound = np.array(lower, np.uint8)\n",
    "        upper_bound = np.array(upper, np.uint8)\n",
    "        mask = cv2.inRange(hsv_image, lower_bound, upper_bound)\n",
    "        filtered_images[color] = cv2.bitwise_and(image, image, mask=mask)\n",
    "    return filtered_images\n",
    "\n",
    "def detect_shapes(image, filtered_images):\n",
    "    detected_shapes = {}\n",
    "    circles = cv2.HoughCircles(cv2.cvtColor(filtered_images['red'], cv2.COLOR_BGR2GRAY), \n",
    "                               cv2.HOUGH_GRADIENT, 1, 20, param1=50, param2=30, minRadius=0, maxRadius=0)\n",
    "    if circles is not None:\n",
    "        detected_shapes['circles'] = np.uint16(np.around(circles))\n",
    "    return detected_shapes\n",
    "\n",
    "def extract_and_match_features(image, database_templates):\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    sift = cv2.SIFT_create()\n",
    "    keypoints, descriptors = sift.detectAndCompute(gray_image, None)\n",
    "    matches = []\n",
    "    for template in database_templates:\n",
    "        template_keypoints, template_descriptors = template\n",
    "        bf = cv2.BFMatcher()\n",
    "        template_matches = bf.knnMatch(descriptors, template_descriptors, k=2)\n",
    "        good_matches = []\n",
    "        for match in template_matches:\n",
    "            if len(match) == 2:\n",
    "                m, n = match\n",
    "                if m.distance < 1 * n.distance:\n",
    "                    good_matches.append(m)\n",
    "        if len(good_matches) > 10:\n",
    "            matches.append((len(good_matches), template))\n",
    "    if not matches:\n",
    "        return None\n",
    "    recognized_sign = max(matches, key=lambda x: x[0])[1]\n",
    "    return recognized_sign\n",
    "\n",
    "def integrate_hsv_shape_with_sift(image, database_templates):\n",
    "    filtered_images = convert_to_hsv_and_filter_by_color(image)\n",
    "    detected_shapes = detect_shapes(image, filtered_images)\n",
    "\n",
    "    for shape, shape_data in detected_shapes.items():\n",
    "        for data in shape_data:\n",
    "            recognized_object = extract_and_match_features(image, database_templates)\n",
    "            if recognized_object:\n",
    "                return recognized_object\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a49fcc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.00%\n"
     ]
    }
   ],
   "source": [
    "def load_data(data_dir):\n",
    "    directories = [d for d in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, d))]\n",
    "    labels = []\n",
    "    images = []\n",
    "    for d in directories:\n",
    "        label_dir = os.path.join(data_dir, d)\n",
    "        file_names = [os.path.join(label_dir, f) for f in os.listdir(label_dir) if f.endswith(\".jpg\")]\n",
    "        for f in file_names:\n",
    "            images.append(skimage.io.imread(f))\n",
    "            labels.append(int(d))\n",
    "    return images, labels\n",
    "\n",
    "def integrate_hsv_shape_with_sift_for_dataset(images, database_templates):\n",
    "    recognized_labels = []\n",
    "    for image in images:\n",
    "        recognized_object = integrate_hsv_shape_with_sift(image, database_templates)\n",
    "        if recognized_object:\n",
    "            recognized_labels.append(recognized_object[0])\n",
    "        else:\n",
    "            recognized_labels.append(None) \n",
    "    return recognized_labels\n",
    "\n",
    "def calculate_accuracy(predicted_labels, true_labels):\n",
    "    correct_matches = 0\n",
    "    for predicted, true in zip(predicted_labels, true_labels):\n",
    "        if predicted == true:\n",
    "            correct_matches += 1\n",
    "    accuracy = correct_matches / len(true_labels) if true_labels else 0\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "train_data_dir = r'C:\\Users\\halil\\Downloads\\GTSRB\\crop_dataset\\crop_dataset'\n",
    "images, labels = load_data(train_data_dir)\n",
    "\n",
    "\n",
    "\n",
    "recognized_labels = integrate_hsv_shape_with_sift_for_dataset(images, database_templates)\n",
    "accuracy = calculate_accuracy(recognized_labels, labels)\n",
    "print(f\"Model Accuracy: {accuracy*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f4adac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
